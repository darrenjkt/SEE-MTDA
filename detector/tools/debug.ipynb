{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae375141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-10 21:46:16,091  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:46:16,091  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:46:16,091  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:46:16,091  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "INFO - 2022-05-10 21:46:16,091 - meshed_kitti_dataset - Loading MeshedKittiDataset dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from cfgs/dataset_configs/da_kitti_dataset_meshed.yaml\n",
      "Using pkl ['infos_meshed_KIT-GM-EXT-PCN-NORMSCALE-COARSE/kitti_infos_val.pkl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-10 21:46:16,271  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-05-10 21:46:16,271  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-05-10 21:46:16,271  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-05-10 21:46:16,271  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "INFO - 2022-05-10 21:46:16,271 - meshed_kitti_dataset - Total samples for MeshedKittiDataset dataset: 3769\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.executable # this should be same in jupyter and command line\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets.kitti.meshed_kitti_dataset import MeshedKittiDataset\n",
    "from pcdet.datasets.baraja.meshed_baraja_dataset import MeshedBarajaDataset\n",
    "from pcdet.datasets.waymo.meshed_waymo_dataset import MeshedWaymoDataset\n",
    "from pcdet.datasets.nuscenes.meshed_nuscenes_dataset import MeshedNuScenesDataset\n",
    "from pcdet.datasets.nuscenes.nuscenes_dataset import NuScenesDataset\n",
    "\n",
    "# cfg_file = '/SEE-MTDA/detector/output/source-waymo/secondiou/see/secondiou_ros_custom1000_GM-ORH005/default/secondiou_ros_custom1000_GM-ORH005_eval-nusc4025.yaml'\n",
    "cfg_file = '/SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/secondiou_ros_custom1000_PCN-norm-coarse.yaml'\n",
    "# cfg_file = '/SEE-MTDA/detector/output/source-waymo/secondiou/baseline/secondiou_custom1000/default/secondiou_custom1000_eval-nusc4025.yaml'\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "\n",
    "__all__ = {\n",
    "    'NuScenesDataset': NuScenesDataset,\n",
    "    'MeshedNuScenesDataset': MeshedNuScenesDataset,\n",
    "    'MeshedKittiDataset': MeshedKittiDataset,\n",
    "    'MeshedWaymoDataset': MeshedWaymoDataset,\n",
    "    'MeshedBarajaDataset': MeshedBarajaDataset\n",
    "}\n",
    "\n",
    "cfg.DATA_CONFIG_TAR.FILTER_MIN_POINTS_IN_GT = 5\n",
    "print(f'Reading from {cfg.DATA_CONFIG_TAR._BASE_CONFIG_}')\n",
    "print(f'Using pkl {cfg.DATA_CONFIG_TAR.INFO_PATH[\"test\"]}')\n",
    "logger = common_utils.create_logger(Path('jupy_log.txt'), rank=cfg.LOCAL_RANK)\n",
    "dataset = __all__[cfg.DATA_CONFIG_TAR.DATASET](\n",
    "        dataset_cfg=cfg.DATA_CONFIG_TAR,\n",
    "        class_names=cfg.DATA_CONFIG_TAR.CLASS_NAMES,\n",
    "        root_path=None,\n",
    "        training=False,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "# cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT = 5\n",
    "# print(f'Using pkl {cfg.DATA_CONFIG.INFO_PATH[\"test\"]}')\n",
    "# logger = common_utils.create_logger(Path('jupy_log.txt'), rank=cfg.LOCAL_RANK)\n",
    "# dataset = __all__[cfg.DATA_CONFIG.DATASET](\n",
    "#         dataset_cfg=cfg.DATA_CONFIG,\n",
    "#         class_names=cfg.CLASS_NAMES,\n",
    "#         root_path=None,\n",
    "#         training=False,\n",
    "#         logger=logger,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "695648b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def convert_to_o3dpcd(points, color=None):\n",
    "    if type(points) == list:\n",
    "        pcds = []\n",
    "        for pointcloud in points:\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(pointcloud[:,:3])\n",
    "            pcds.append(pcd)\n",
    "        return pcds\n",
    "    else:\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points[:,:3])\n",
    "        if color:\n",
    "            pcd.paint_uniform_color(color)\n",
    "        return pcd\n",
    "\n",
    "def opd_to_boxpts(box):\n",
    "    \"\"\"\n",
    "    Takes an array containing [x,y,z,l,w,h,r], and returns an [8, 3] matrix that \n",
    "    represents the [x, y, z] for each 8 corners of the box.\n",
    "    \n",
    "    Note: Openpcdet __getitem__ gt_boxes are in the format [x,y,z,l,w,h,r,alpha]\n",
    "    where alpha is \"observation angle of object, ranging [-pi..pi]\"\n",
    "    \"\"\"\n",
    "    # To return\n",
    "    corner_boxes = np.zeros((8, 3))\n",
    "\n",
    "    translation = box[0:3]\n",
    "    l, w, h = box[3], box[4], box[5] # waymo, nusc, kitti is all l,w,h after OpenPCDet processing\n",
    "    rotation = box[6]\n",
    "\n",
    "    # Create a bounding box outline\n",
    "    bounding_box = np.array([[l/2, w/2, h/2],\n",
    "                             [l/2, -w/2, h/2],\n",
    "                             [-l/2, w/2, h/2],\n",
    "                             [-l/2, -w/2, h/2],\n",
    "                             [l/2, w/2, -h/2],\n",
    "                             [l/2, -w/2, -h/2],\n",
    "                             [-l/2, w/2, -h/2],\n",
    "                             [-l/2, -w/2, -h/2]])\n",
    "\n",
    "    # Standard 3x3 rotation matrix around the Z axis\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(rotation), np.sin(rotation), 0.0],\n",
    "        [-np.sin(rotation), np.cos(rotation), 0.0],\n",
    "        [0.0, 0.0, 1.0]])\n",
    "    vcbox = bounding_box @ rotation_matrix\n",
    "    vcbox += box[:3]\n",
    "    \n",
    "    return vcbox\n",
    "\n",
    "def boxpts_to_o3dbox(box_pts, colour=None):\n",
    "    boxpts = o3d.utility.Vector3dVector(box_pts)\n",
    "    o3dbox = o3d.geometry.OrientedBoundingBox().create_from_points(boxpts)\n",
    "    if colour is None:\n",
    "        colour = [1,0,0]\n",
    "        \n",
    "    o3dbox.color = np.array(colour)\n",
    "    return o3dbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595bdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_3d(text, pos, direction=None, degree=90.0, density=10, font='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', font_size=16):\n",
    "    \"\"\"\n",
    "    Code from https://github.com/isl-org/Open3D/issues/2\n",
    "    \n",
    "    Generate a 3D text point cloud used for visualization.\n",
    "    :param text: content of the text\n",
    "    :param pos: 3D xyz position of the text upper left corner\n",
    "    :param direction: 3D normalized direction of where the text faces\n",
    "    :param degree: in plane rotation of text\n",
    "    :param font: Name of the font - change it according to your system\n",
    "    :param font_size: size of the font\n",
    "    :return: o3d.geoemtry.PointCloud object\n",
    "    \"\"\"\n",
    "    if direction is None:\n",
    "        direction = (1., 0., 0.)\n",
    "\n",
    "    from PIL import Image, ImageFont, ImageDraw\n",
    "    from pyquaternion import Quaternion\n",
    "\n",
    "    font_obj = ImageFont.truetype(font, font_size * density)\n",
    "    font_dim = font_obj.getsize(text)\n",
    "\n",
    "    img = Image.new('RGB', font_dim, color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((0, 0), text, font=font_obj, fill=(0, 0, 0))\n",
    "    img = np.asarray(img)\n",
    "    img_mask = img[:, :, 0] < 128\n",
    "    indices = np.indices([*img.shape[0:2], 1])[:, img_mask, 0].reshape(3, -1).T\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.colors = o3d.utility.Vector3dVector(img[img_mask, :].astype(float) / 255.0)\n",
    "    pcd.points = o3d.utility.Vector3dVector(indices / 1000 / density)\n",
    "\n",
    "    raxis = np.cross([0.0, 0.0, 1.0], direction)\n",
    "    if np.linalg.norm(raxis) < 1e-6:\n",
    "        raxis = (0.0, 0.0, 1.0)\n",
    "    trans = (Quaternion(axis=raxis, radians=np.arccos(direction[2])) *\n",
    "             Quaternion(axis=direction, degrees=degree)).transformation_matrix\n",
    "    trans[0:3, 3] = np.asarray(pos)\n",
    "    pcd.transform(trans)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86ed5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = dataset.__getitem__(47) # 1637, 167\n",
    "\n",
    "opcd = convert_to_o3dpcd(in_dict['points'])\n",
    "o3dboxes = [boxpts_to_o3dbox(opd_to_boxpts(box)) for box in in_dict['gt_boxes']]\n",
    "\n",
    "objs = [opcd.crop(o3dbox) for o3dbox in o3dboxes]\n",
    "text_loc = [o3dbox.center + np.array([0,0,o3dbox.extent[2]]) for o3dbox in o3dboxes]\n",
    "num_pts = [len(obj.points) for obj in objs]\n",
    "labels = [text_3d(str(npt), loc, font_size=500, density=1) for npt, loc in zip(num_pts, text_loc)]\n",
    "\n",
    "o3d.visualization.draw_geometries([opcd] + o3dboxes + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fb02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_points_by_range(points, limit_range):\n",
    "    # Input: [xmin, ymin, zmin, xmax, ymax, zmax] \n",
    "    # Though this only limits x and y\n",
    "    mask = (points[:, 0] >= limit_range[0]) & (points[:, 0] <= limit_range[3]) \\\n",
    "           & (points[:, 1] >= limit_range[1]) & (points[:, 1] <= limit_range[4])\n",
    "    return mask\n",
    "\n",
    "LIMITS = [-24, -24, -2, 24, 24, 4]\n",
    "pts = in_dict['points'][mask_points_by_range(in_dict['points'], LIMITS)]\n",
    "limpcd = convert_to_o3dpcd(pts, [0.9,0.9,0])\n",
    "o3d.visualization.draw_geometries([opcd, limpcd] + o3dboxes + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "196b2f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'points': array([[ -3.4035199 , -12.885465  ,   0.0545764 ],\n",
      "       [ -3.665458  , -12.484063  ,   0.10108173],\n",
      "       [ -3.8360603 , -12.696234  ,   0.6848511 ],\n",
      "       ...,\n",
      "       [-19.87915   ,  -0.20320109,   3.9118257 ],\n",
      "       [-19.831064  ,  -0.19266169,   4.844988  ],\n",
      "       [-19.822323  ,  -0.18565044,   5.321441  ]], dtype=float32), 'frame_id': 'f552ec59c267469899b3472d6bd9bf1d#000213', 'metadata': {'token': 'f552ec59c267469899b3472d6bd9bf1d'}, 'num_lidar_pts': array([1665,   11,    4,   10,    5,    4,   18,    5,    3,    3,    7,\n",
      "          4,  116,    3,   11,    6,    4,   15,    3,  143,   40,   10,\n",
      "          9,   37,    3,    8]), 'num_meshed_lidar_pts': array([4420,   22,   13,   20,    9,   10,   37,    8,    5,    7,   12,\n",
      "          4, 1020,    5,   21,   11,    8,   30,   10, 1018,  441,   21,\n",
      "         17,  499,    6,   18]), 'gt_names': array(['car', 'motorcycle', 'bicycle', 'car', 'car', 'car', 'car', 'car',\n",
      "       'car', 'pedestrian', 'motorcycle', 'car', 'car', 'traffic_cone',\n",
      "       'car', 'traffic_cone', 'car', 'car', 'motorcycle', 'car', 'car',\n",
      "       'car', 'pedestrian', 'car', 'pedestrian', 'car'], dtype='<U12'), 'gt_boxes': array([[ 5.64029416e+00, -1.58981495e+00, -9.52986643e-01,\n",
      "         4.35900000e+00,  1.80700000e+00,  2.05600000e+00,\n",
      "        -1.52983243e+00, -1.82394897e-02,  8.86047377e-02],\n",
      "       [-2.77069376e+00, -2.15351498e+01, -1.54952048e+00,\n",
      "         2.41700000e+00,  9.13000000e-01,  1.51400000e+00,\n",
      "        -1.43369634e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [-2.31821897e+01, -5.48907218e-01, -5.69655688e-01,\n",
      "         1.54100000e+00,  6.49000000e-01,  1.11700000e+00,\n",
      "         3.13197454e+00,  8.73326928e-04, -8.23174215e-03],\n",
      "       [ 2.77206269e+01, -3.02803503e+01, -2.29951925e+00,\n",
      "         4.84800000e+00,  2.01500000e+00,  1.99900000e+00,\n",
      "         4.30234044e-01, -5.30386176e-03, -2.89657912e-03],\n",
      "       [-1.04103042e+01, -2.15455417e+01, -1.11585538e+00,\n",
      "         3.95600000e+00,  1.80800000e+00,  1.46700000e+00,\n",
      "        -3.12625011e+00, -8.77379214e-03,  2.99981344e-02],\n",
      "       [ 9.49490947e+00, -6.36707406e+01, -2.46135120e+00,\n",
      "         4.71300000e+00,  2.01200000e+00,  1.65400000e+00,\n",
      "        -2.92112017e+00,  3.03367158e-02,  1.67426970e-02],\n",
      "       [-4.88692821e+00, -3.47609428e+01, -1.40471392e+00,\n",
      "         4.55900000e+00,  1.73800000e+00,  1.95100000e+00,\n",
      "        -2.56772208e-02, -3.28730501e-02,  3.02580940e-02],\n",
      "       [-2.19211586e+01, -1.47650387e+01, -7.29408825e-01,\n",
      "         4.45600000e+00,  1.85400000e+00,  1.57900000e+00,\n",
      "        -6.35223930e-02,  2.44642443e-02,  4.70374369e-02],\n",
      "       [-5.11999055e+00, -4.42636443e+01, -1.78870832e+00,\n",
      "         4.31700000e+00,  1.70000000e+00,  1.61200000e+00,\n",
      "         3.13337096e+00,  5.08981378e-02, -9.39841996e-05],\n",
      "       [-1.36636920e+01, -1.46111730e+01, -6.75235776e-01,\n",
      "         6.75000000e-01,  7.41000000e-01,  1.88400000e+00,\n",
      "         1.07115949e+00,  8.67702938e-02, -2.45404591e-02],\n",
      "       [-3.66026119e+00, -2.18159423e+01, -1.52649019e+00,\n",
      "         2.31700000e+00,  7.44000000e-01,  1.62000000e+00,\n",
      "        -1.43552913e+00, -2.77308842e-03, -3.20912239e-03],\n",
      "       [ 1.26742500e+01, -3.68308191e+01, -2.04528575e+00,\n",
      "         4.39100000e+00,  1.91400000e+00,  1.88600000e+00,\n",
      "         3.75387208e-01, -1.06529020e-02, -3.47135960e-02],\n",
      "       [-1.05826055e+01, -1.33961549e+01, -9.13004122e-01,\n",
      "         4.66200000e+00,  1.81500000e+00,  1.60600000e+00,\n",
      "        -3.12625011e+00,  2.97364420e-02,  4.34159082e-02],\n",
      "       [-2.55232608e+01,  6.13595000e+00,  1.04247714e+00,\n",
      "         2.97000000e-01,  3.11000000e-01,  1.00100000e+00,\n",
      "        -1.71239013e-01, -5.61507613e-03,  1.97899361e-02],\n",
      "       [-2.24885093e+01, -1.98128079e+01, -8.16172579e-01,\n",
      "         4.44500000e+00,  1.76600000e+00,  1.63500000e+00,\n",
      "        -8.07175163e-02,  3.01999148e-03,  5.06098590e-02],\n",
      "       [ 1.06763998e+01,  3.66174527e+00, -1.26522706e+00,\n",
      "         3.15000000e-01,  3.12000000e-01,  9.70000000e-01,\n",
      "         2.13501061e+00, -3.57301336e-02,  5.61178448e-02],\n",
      "       [-2.17690347e+01, -2.24764589e+01, -9.00321146e-01,\n",
      "         3.93300000e+00,  1.85600000e+00,  1.58800000e+00,\n",
      "        -1.08923554e-02,  4.62781183e-02,  5.24758590e-02],\n",
      "       [-5.68922619e+00, -1.63470714e+01, -1.13593993e+00,\n",
      "         4.55100000e+00,  1.76200000e+00,  1.84200000e+00,\n",
      "        -3.12625011e+00,  1.15659149e-03, -6.35992960e-02],\n",
      "       [-3.02302665e+00, -2.58140285e+01, -1.73679355e+00,\n",
      "         2.13500000e+00,  8.05000000e-01,  1.39200000e+00,\n",
      "        -1.54114163e+00,  0.00000000e+00,  0.00000000e+00],\n",
      "       [-5.47455749e+00, -1.32944291e+01, -1.06233216e+00,\n",
      "         4.19800000e+00,  1.77300000e+00,  1.70100000e+00,\n",
      "        -3.10879568e+00, -6.44600762e-03,  7.84252770e-02],\n",
      "       [-2.09843371e+01,  8.45488940e+00,  8.06297230e-02,\n",
      "         4.53900000e+00,  1.83300000e+00,  1.57800000e+00,\n",
      "        -3.12593593e+00,  1.81993740e-04,  5.96275434e-02],\n",
      "       [-1.07078748e+01, -1.66736791e+01, -1.07012790e+00,\n",
      "         4.04200000e+00,  1.79400000e+00,  1.48900000e+00,\n",
      "         3.11504264e+00, -9.55041875e-02,  1.46050762e-01],\n",
      "       [ 8.85246818e+00,  2.04116271e+01, -3.82814265e-01,\n",
      "         1.03400000e+00,  7.63000000e-01,  1.89800000e+00,\n",
      "         1.76220165e+00, -3.28463712e-01,  1.02188023e+00],\n",
      "       [-2.15378676e+01, -1.22421946e+01, -6.77488937e-01,\n",
      "         4.47700000e+00,  1.90700000e+00,  1.48900000e+00,\n",
      "        -8.55706356e-02, -1.44306864e-02,  4.23572138e-02],\n",
      "       [-2.86961238e+01,  5.79643393e+00,  1.36965038e+00,\n",
      "         6.87000000e-01,  6.71000000e-01,  1.93000000e+00,\n",
      "         2.90383017e+00, -3.50576523e-01, -1.86228284e-02],\n",
      "       [-2.19393722e+01, -1.74584969e+01, -7.99532789e-01,\n",
      "         4.16700000e+00,  1.88800000e+00,  1.52100000e+00,\n",
      "        -1.08923554e-02,  4.80201836e-03,  1.07796258e-02]])}\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "\n",
    "index = 213\n",
    "info = copy.deepcopy(dataset.infos[index])\n",
    "points = dataset.get_meshed_lidar(index)\n",
    "\n",
    "# Shift points \n",
    "if dataset.dataset_cfg.get('SHIFT_COOR', None):\n",
    "    points[:, 0:3] += np.array(dataset.dataset_cfg.SHIFT_COOR, dtype=np.float32)\n",
    "\n",
    "input_dict = {\n",
    "    'points': points,\n",
    "    'frame_id': Path(info['meshed_lidar_path']).stem,\n",
    "    'metadata': {'token': info['token']},\n",
    "    'num_lidar_pts': info['num_lidar_pts'],\n",
    "    'num_meshed_lidar_pts': info['num_meshed_lidar_pts'],\n",
    "    'gt_names': info['gt_names']\n",
    "}\n",
    "\n",
    "if 'gt_boxes' in info:\n",
    "    if dataset.dataset_cfg.get('FILTER_MIN_POINTS_IN_GT', False):\n",
    "        mask = (info['num_lidar_pts'] > dataset.dataset_cfg.FILTER_MIN_POINTS_IN_GT)\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    input_dict.update({\n",
    "        'gt_names': info['gt_names'] if mask is None else info['gt_names'][mask],\n",
    "        'gt_boxes': info['gt_boxes'] if mask is None else info['gt_boxes'][mask],\n",
    "        'num_lidar_pts': info['num_lidar_pts'] if mask is None else info['num_lidar_pts'][mask],\n",
    "        'num_meshed_lidar_pts': info['num_meshed_lidar_pts'] if mask is None else info['num_meshed_lidar_pts'][mask]\n",
    "    })\n",
    "    \n",
    "print(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e92df",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0254b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-10 21:47:39,524  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:47:39,524  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:47:39,524  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:47:39,524  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "INFO - 2022-05-10 21:47:39,524 - meshed_kitti_dataset - Loading MeshedKittiDataset dataset\n",
      "[2022-05-10 21:47:39,677  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-05-10 21:47:39,677  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-05-10 21:47:39,677  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-05-10 21:47:39,677  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "INFO - 2022-05-10 21:47:39,677 - meshed_kitti_dataset - Total samples for MeshedKittiDataset dataset: 3769\n"
     ]
    }
   ],
   "source": [
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network\n",
    "\n",
    "ckpt_path = '/SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/checkpoint_epoch_82.pth'\n",
    "# ckpt_path = '/SEE-MTDA/model_zoo/waymo_secondiou_baseline_1192.pth'\n",
    "\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "            dataset_cfg=cfg.DATA_CONFIG_TAR,\n",
    "            class_names=cfg.DATA_CONFIG_TAR.CLASS_NAMES,\n",
    "            batch_size=1,\n",
    "            dist=False, workers=2, logger=logger, training=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bc5b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = '/SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/ckpt-best.pth'\n",
    "'ckpt-best' in mypath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d442913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(ckpt_path).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe82b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "989e13f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'it', 'model_state', 'optimizer_state', 'version'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c058a3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-10 21:47:39,828  detector3d_template.py 325  INFO]  ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/checkpoint_epoch_82.pth to GPU\n",
      "[2022-05-10 21:47:39,828  detector3d_template.py 325  INFO]  ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/checkpoint_epoch_82.pth to GPU\n",
      "[2022-05-10 21:47:39,828  detector3d_template.py 325  INFO]  ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/checkpoint_epoch_82.pth to GPU\n",
      "[2022-05-10 21:47:39,828  detector3d_template.py 325  INFO]  ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/checkpoint_epoch_82.pth to GPU\n",
      "INFO - 2022-05-10 21:47:39,828 - detector3d_template - ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/ckpt/checkpoint_epoch_82.pth to GPU\n",
      "[2022-05-10 21:47:41,861  detector3d_template.py 331  INFO]  ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "[2022-05-10 21:47:41,861  detector3d_template.py 331  INFO]  ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "[2022-05-10 21:47:41,861  detector3d_template.py 331  INFO]  ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "[2022-05-10 21:47:41,861  detector3d_template.py 331  INFO]  ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "INFO - 2022-05-10 21:47:41,861 - detector3d_template - ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "[2022-05-10 21:47:42,041  detector3d_template.py 350  INFO]  ==> Done (loaded 189/189)\n",
      "[2022-05-10 21:47:42,041  detector3d_template.py 350  INFO]  ==> Done (loaded 189/189)\n",
      "[2022-05-10 21:47:42,041  detector3d_template.py 350  INFO]  ==> Done (loaded 189/189)\n",
      "[2022-05-10 21:47:42,041  detector3d_template.py 350  INFO]  ==> Done (loaded 189/189)\n",
      "INFO - 2022-05-10 21:47:42,041 - detector3d_template - ==> Done (loaded 189/189)\n"
     ]
    }
   ],
   "source": [
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=False)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b735cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3448: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "from pcdet.models import load_data_to_gpu\n",
    "\n",
    "def statistics_info(cfg, ret_dict, metric, disp_dict):\n",
    "    for cur_thresh in cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST:\n",
    "        metric['recall_roi_%s' % str(cur_thresh)] += ret_dict.get('roi_%s' % str(cur_thresh), 0)\n",
    "        metric['recall_rcnn_%s' % str(cur_thresh)] += ret_dict.get('rcnn_%s' % str(cur_thresh), 0)\n",
    "    metric['gt_num'] += ret_dict.get('gt', 0)\n",
    "    min_thresh = cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST[0]\n",
    "    disp_dict['recall_%s' % str(min_thresh)] = \\\n",
    "        '(%d, %d) / %d' % (metric['recall_roi_%s' % str(min_thresh)], metric['recall_rcnn_%s' % str(min_thresh)], metric['gt_num'])\n",
    "\n",
    "metric = {\n",
    "    'gt_num': 0,\n",
    "}\n",
    "det_annos = []\n",
    "for cur_thresh in cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST:\n",
    "    metric['recall_roi_%s' % str(cur_thresh)] = 0\n",
    "    metric['recall_rcnn_%s' % str(cur_thresh)] = 0\n",
    "\n",
    "\n",
    "for i, batch_dict in enumerate(test_loader):\n",
    "    if i < 20:\n",
    "        load_data_to_gpu(batch_dict)\n",
    "        with torch.no_grad():\n",
    "            pred_dicts, ret_dict = model(batch_dict)\n",
    "        disp_dict = {}\n",
    "\n",
    "        statistics_info(cfg, ret_dict, metric, disp_dict)\n",
    "        annos = dataset.generate_prediction_dicts(\n",
    "            batch_dict, pred_dicts, class_names,\n",
    "            output_path=None\n",
    "        )\n",
    "        det_annos += annos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fcdb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/SEE-MTDA/detector/output/source-nuscenes/secondiou/see-v2/secondiou_ros_PCN-norm-coarse/eval/eval_all_default/default/epoch_134/val/result_dict.pkl', 'rb') as f:\n",
    "    res = pickle.load(f)\n",
    "# 'Car_3d/moderate_R40'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ded75be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Car_aos/easy_R40': 96.96647654132234,\n",
       " 'Car_aos/moderate_R40': 94.52864579283711,\n",
       " 'Car_aos/hard_R40': 97.02194298208322,\n",
       " 'Car_3d/easy_R40': 67.38243672543798,\n",
       " 'Car_3d/moderate_R40': 61.75487685752435,\n",
       " 'Car_3d/hard_R40': 62.53479497279033,\n",
       " 'Car_bev/easy_R40': 89.30661533108474,\n",
       " 'Car_bev/moderate_R40': 85.65395898111842,\n",
       " 'Car_bev/hard_R40': 86.53882710036704,\n",
       " 'Car_image/easy_R40': 96.97348182138954,\n",
       " 'Car_image/moderate_R40': 94.54188147375116,\n",
       " 'Car_image/hard_R40': 97.0590166158118}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11667869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall/roi_0.3': 0.9610598434004475,\n",
       " 'recall/rcnn_0.3': 0.9610598434004475,\n",
       " 'recall/roi_0.5': 0.9525307606263982,\n",
       " 'recall/rcnn_0.5': 0.9525307606263982,\n",
       " 'recall/roi_0.7': 0.7220357941834452,\n",
       " 'recall/rcnn_0.7': 0.7220357941834452,\n",
       " 'Car_aos/easy_R40': 96.96647654132234,\n",
       " 'Car_aos/moderate_R40': 94.52864579283711,\n",
       " 'Car_aos/hard_R40': 97.02194298208322,\n",
       " 'Car_3d/easy_R40': 67.38243672543798,\n",
       " 'Car_3d/moderate_R40': 61.75487685752435,\n",
       " 'Car_3d/hard_R40': 62.53479497279033,\n",
       " 'Car_bev/easy_R40': 89.30661533108474,\n",
       " 'Car_bev/moderate_R40': 85.65395898111842,\n",
       " 'Car_bev/hard_R40': 86.53882710036704,\n",
       " 'Car_image/easy_R40': 96.97348182138954,\n",
       " 'Car_image/moderate_R40': 94.54188147375116,\n",
       " 'Car_image/hard_R40': 97.0590166158118}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be6d63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = dataset.__getitem__(i) # 1637, 167\n",
    "\n",
    "gt_boxes = batch_dict['gt_boxes'].squeeze(0).cpu().numpy()\n",
    "pred_boxes = pred_dicts[0]['pred_boxes'].cpu().numpy()\n",
    "\n",
    "o3d_gtb = [boxpts_to_o3dbox(opd_to_boxpts(box),[0,0,1]) for box in gt_boxes]\n",
    "o3d_pb = [boxpts_to_o3dbox(opd_to_boxpts(box),[0,0.7,0]) for box in pred_boxes]\n",
    "opcd = convert_to_o3dpcd(in_dict['points'])\n",
    "\n",
    "o3d.visualization.draw_geometries(o3d_gtb + o3d_pb + [opcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e3f89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = dataset.__getitem__(i) # 1637, 167\n",
    "\n",
    "opcd = convert_to_o3dpcd(in_dict['points'])\n",
    "o3dboxes = [boxpts_to_o3dbox(opd_to_boxpts(box)) for box in in_dict['gt_boxes']]\n",
    "\n",
    "objs = [opcd.crop(o3dbox) for o3dbox in o3dboxes]\n",
    "text_loc = [o3dbox.center + np.array([0,0,o3dbox.extent[2]]) for o3dbox in o3dboxes]\n",
    "num_pts = [len(obj.points) for obj in objs]\n",
    "labels = [text_3d(str(npt), loc, font_size=500, density=1) for npt, loc in zip(num_pts, text_loc)]\n",
    "\n",
    "o3d.visualization.draw_geometries([opcd] + o3dboxes + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e5397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from ../../data/nuscenes/custom_t4025-v3980/infos_meshed_NUS-DM-ORH005/nuscenes_infos_2sweeps_val.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for info_path in dataset.dataset_cfg.INFO_PATH['test']:\n",
    "    info_path = dataset.root_path / info_path\n",
    "    print(f'Reading from {info_path}')\n",
    "    if not info_path.exists():\n",
    "        continue\n",
    "    with open(info_path, 'rb') as f:\n",
    "        infos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "195af475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 3980/3980 [01:02<00:00, 63.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import open3d as o3d\n",
    "\n",
    "updated_infos = []\n",
    "\n",
    "for i in tqdm(range(len(infos)), total=len(infos)):\n",
    "    info = infos[i]\n",
    "    meshed_lidar_file = dataset.root_path / info['meshed_lidar_path']\n",
    "    opcd = o3d.io.read_point_cloud(str(meshed_lidar_file))\n",
    "    gt_boxes = info['gt_boxes']\n",
    "    o3dboxes = [boxpts_to_o3dbox(opd_to_boxpts(box)) for box in gt_boxes]\n",
    "    objs = [opcd.crop(o3dbox) for o3dbox in o3dboxes]    \n",
    "    num_pts = [len(obj.points) for obj in objs]\n",
    "#     text_loc = [o3dbox.center + np.array([0,0,o3dbox.extent[2]]) for o3dbox in o3dboxes]\n",
    "#     labels = [text_3d(str(npt), loc, font_size=500, density=1) for npt, loc in zip(num_pts, text_loc)]\n",
    "    info['num_meshed_lidar_pts'] = np.array(num_pts)\n",
    "    updated_infos.append(info)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadd2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toutput = open(str(Path(dataset.dataset_cfg.DATA_PATH).absolute() / 'infos_meshed_NUS-DM-ORH005' / f'nuscenes_infos_2sweeps_val_meshednum.pkl'), 'wb')\n",
    "pickle.dump(updated_infos, toutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da5d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([opcd] + o3dboxes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "896b9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('car', 3, 6)\n",
      "('traffic_cone', 19, 38)\n",
      "('car', 63, 461)\n",
      "('car', 18, 32)\n",
      "('barrier', 2, 4)\n",
      "('pedestrian', 5, 12)\n",
      "('car', 4, 7)\n",
      "('pedestrian', 19, 35)\n",
      "('car', 10, 23)\n",
      "('car', 1, 4)\n",
      "('car', 5, 9)\n",
      "('car', 2, 3)\n",
      "('car', 8, 15)\n",
      "('traffic_cone', 9, 17)\n",
      "('pedestrian', 5, 10)\n",
      "('barrier', 6, 13)\n",
      "('traffic_cone', 2, 3)\n",
      "('truck', 8, 15)\n",
      "('car', 7, 17)\n",
      "('car', 19, 49)\n",
      "('car', 16, 32)\n",
      "('car', 1, 2)\n",
      "('car', 4, 9)\n",
      "('pedestrian', 1, 8)\n",
      "('barrier', 3, 6)\n",
      "('car', 2, 4)\n",
      "('car', 3, 10)\n",
      "('car', 8, 20)\n",
      "('barrier', 6, 14)\n",
      "('pedestrian', 5, 10)\n",
      "('pedestrian', 5, 10)\n",
      "('ignore', 8, 16)\n",
      "('car', 6, 10)\n",
      "('car', 10, 22)\n",
      "('car', 2, 4)\n",
      "('barrier', 25, 50)\n",
      "('barrier', 27, 50)\n",
      "('car', 9, 17)\n",
      "('car', 1, 2)\n",
      "('car', 1, 4)\n",
      "('traffic_cone', 4, 6)\n",
      "('car', 3, 8)\n",
      "('pedestrian', 12, 23)\n",
      "('car', 2, 4)\n",
      "('car', 4, 8)\n",
      "('car', 30, 322)\n",
      "('car', 5, 9)\n",
      "('barrier', 15, 31)\n",
      "('barrier', 8, 16)\n",
      "('car', 2, 4)\n",
      "('barrier', 11, 21)\n",
      "('car', 1, 2)\n",
      "('pedestrian', 4, 9)\n",
      "('car', 2, 5)\n",
      "('car', 99, 678)\n",
      "('car', 2, 4)\n",
      "('car', 2, 4)\n",
      "('car', 596, 2117)\n",
      "('car', 1, 1)\n",
      "('car', 1, 2)\n",
      "('traffic_cone', 5, 8)\n",
      "('car', 10, 14)\n",
      "('pedestrian', 17, 35)\n",
      "('car', 3, 4)\n",
      "('car', 4, 6)\n",
      "('barrier', 14, 32)\n",
      "('car', 0, 0)\n",
      "('car', 5, 4)\n",
      "('barrier', 1, 1)\n",
      "('barrier', 34, 77)\n",
      "('car', 7, 15)\n"
     ]
    }
   ],
   "source": [
    "for d in zip(info['gt_names'], info['num_lidar_pts'], info['num_meshed_lidar_pts']):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2253fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51d926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

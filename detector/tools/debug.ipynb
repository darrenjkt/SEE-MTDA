{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae375141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pkl ['infos_meshed_WAY-GM-EXT_R6D-E3_SURFACEKNN_CN/waymo_infos_train.pkl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-19 22:49:02,074  meshed_waymo_dataset.py 45  INFO]  Loading Waymo dataset\n",
      "[2022-06-19 22:49:02,074  meshed_waymo_dataset.py 45  INFO]  Loading Waymo dataset\n",
      "INFO - 2022-06-19 22:49:02,074 - meshed_waymo_dataset - Loading Waymo dataset\n",
      "[2022-06-19 22:49:03,277  meshed_waymo_dataset.py 60  INFO]  Total skipped info 0\n",
      "[2022-06-19 22:49:03,277  meshed_waymo_dataset.py 60  INFO]  Total skipped info 0\n",
      "INFO - 2022-06-19 22:49:03,277 - meshed_waymo_dataset - Total skipped info 0\n",
      "[2022-06-19 22:49:03,283  meshed_waymo_dataset.py 61  INFO]  Total samples for Waymo dataset: 1000\n",
      "[2022-06-19 22:49:03,283  meshed_waymo_dataset.py 61  INFO]  Total samples for Waymo dataset: 1000\n",
      "INFO - 2022-06-19 22:49:03,283 - meshed_waymo_dataset - Total samples for Waymo dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.executable # this should be same in jupyter and command line\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pcdet.utils import common_utils\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.datasets.kitti.meshed_kitti_dataset import MeshedKittiDataset\n",
    "from pcdet.datasets.baraja.meshed_baraja_dataset import MeshedBarajaDataset\n",
    "from pcdet.datasets.waymo.meshed_waymo_dataset import MeshedWaymoDataset\n",
    "from pcdet.datasets.nuscenes.meshed_nuscenes_dataset import MeshedNuScenesDataset\n",
    "from pcdet.datasets.nuscenes.nuscenes_dataset import NuScenesDataset\n",
    "\n",
    "# cfg_file = '/SEE-MTDA/detector/output/source-waymo/secondiou/see/secondiou_ros_custom1000_GM-ORH005/default/secondiou_ros_custom1000_GM-ORH005_eval-nusc4025.yaml'\n",
    "# cfg_file = '/SEE-MTDA/detector/output/source-waymo/secondiou/see-v2/secondiou_ros_custom1000_PCN-norm-coarse/default/secondiou_ros_custom1000_PCN-norm-coarse.yaml'\n",
    "# cfg_file = '/SEE-MTDA/detector/output/source-waymo/secondiou/baseline/secondiou_custom1000/default/secondiou_custom1000_eval-nusc4025.yaml'\n",
    "cfg_file = '/SEE-MTDA/detector/output/source-waymo/pvrcnn/see-v2/pvrcnn_ros_custom1000_WAY-GM-EXT-R6D-E3_SURFACEKNN_CN_150ep/default/pvrcnn_ros_custom1000_WAY-GM-EXT-R6D-E3_SURFACEKNN_CN.yaml'\n",
    "\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "\n",
    "__all__ = {\n",
    "    'NuScenesDataset': NuScenesDataset,\n",
    "    'MeshedNuScenesDataset': MeshedNuScenesDataset,\n",
    "    'MeshedKittiDataset': MeshedKittiDataset,\n",
    "    'MeshedWaymoDataset': MeshedWaymoDataset,\n",
    "    'MeshedBarajaDataset': MeshedBarajaDataset\n",
    "}\n",
    "\n",
    "# cfg.DATA_CONFIG_TAR.FILTER_MIN_POINTS_IN_GT = 5\n",
    "# print(f'Reading from {cfg.DATA_CONFIG_TAR._BASE_CONFIG_}')\n",
    "# print(f'Using pkl {cfg.DATA_CONFIG_TAR.INFO_PATH[\"test\"]}')\n",
    "# logger = common_utils.create_logger(Path('jupy_log.txt'), rank=cfg.LOCAL_RANK)\n",
    "# dataset = __all__[cfg.DATA_CONFIG_TAR.DATASET](\n",
    "#         dataset_cfg=cfg.DATA_CONFIG_TAR,\n",
    "#         class_names=cfg.DATA_CONFIG_TAR.CLASS_NAMES,\n",
    "#         root_path=None,\n",
    "#         training=False,\n",
    "#         logger=logger,\n",
    "#     )\n",
    "\n",
    "cfg.DATA_CONFIG.FILTER_MIN_POINTS_IN_GT = 5\n",
    "print(f'Using pkl {cfg.DATA_CONFIG.INFO_PATH[\"test\"]}')\n",
    "logger = common_utils.create_logger(Path('jupy_log.txt'), rank=cfg.LOCAL_RANK)\n",
    "dataset = __all__[cfg.DATA_CONFIG.DATASET](\n",
    "        dataset_cfg=cfg.DATA_CONFIG,\n",
    "        class_names=cfg.CLASS_NAMES,\n",
    "        root_path=None,\n",
    "        training=False,\n",
    "        logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695648b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def convert_to_o3dpcd(points, color=None):\n",
    "    if type(points) == list:\n",
    "        pcds = []\n",
    "        for pointcloud in points:\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(pointcloud[:,:3])\n",
    "            pcds.append(pcd)\n",
    "        return pcds\n",
    "    else:\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(points[:,:3])\n",
    "        if color:\n",
    "            pcd.paint_uniform_color(color)\n",
    "        return pcd\n",
    "\n",
    "def opd_to_boxpts(box):\n",
    "    \"\"\"\n",
    "    Takes an array containing [x,y,z,l,w,h,r], and returns an [8, 3] matrix that \n",
    "    represents the [x, y, z] for each 8 corners of the box.\n",
    "    \n",
    "    Note: Openpcdet __getitem__ gt_boxes are in the format [x,y,z,l,w,h,r,alpha]\n",
    "    where alpha is \"observation angle of object, ranging [-pi..pi]\"\n",
    "    \"\"\"\n",
    "    # To return\n",
    "    corner_boxes = np.zeros((8, 3))\n",
    "\n",
    "    translation = box[0:3]\n",
    "    l, w, h = box[3], box[4], box[5] # waymo, nusc, kitti is all l,w,h after OpenPCDet processing\n",
    "    rotation = box[6]\n",
    "\n",
    "    # Create a bounding box outline\n",
    "    bounding_box = np.array([[l/2, w/2, h/2],\n",
    "                             [l/2, -w/2, h/2],\n",
    "                             [-l/2, w/2, h/2],\n",
    "                             [-l/2, -w/2, h/2],\n",
    "                             [l/2, w/2, -h/2],\n",
    "                             [l/2, -w/2, -h/2],\n",
    "                             [-l/2, w/2, -h/2],\n",
    "                             [-l/2, -w/2, -h/2]])\n",
    "\n",
    "    # Standard 3x3 rotation matrix around the Z axis\n",
    "    rotation_matrix = np.array([\n",
    "        [np.cos(rotation), np.sin(rotation), 0.0],\n",
    "        [-np.sin(rotation), np.cos(rotation), 0.0],\n",
    "        [0.0, 0.0, 1.0]])\n",
    "    vcbox = bounding_box @ rotation_matrix\n",
    "    vcbox += box[:3]\n",
    "    \n",
    "    return vcbox\n",
    "\n",
    "def boxpts_to_o3dbox(box_pts, colour=None):\n",
    "    boxpts = o3d.utility.Vector3dVector(box_pts)\n",
    "    o3dbox = o3d.geometry.OrientedBoundingBox().create_from_points(boxpts)\n",
    "    if colour is None:\n",
    "        colour = [1,0,0]\n",
    "        \n",
    "    o3dbox.color = np.array(colour)\n",
    "    return o3dbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595bdafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_3d(text, pos, direction=None, degree=90.0, density=10, font='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', font_size=16):\n",
    "    \"\"\"\n",
    "    Code from https://github.com/isl-org/Open3D/issues/2\n",
    "    \n",
    "    Generate a 3D text point cloud used for visualization.\n",
    "    :param text: content of the text\n",
    "    :param pos: 3D xyz position of the text upper left corner\n",
    "    :param direction: 3D normalized direction of where the text faces\n",
    "    :param degree: in plane rotation of text\n",
    "    :param font: Name of the font - change it according to your system\n",
    "    :param font_size: size of the font\n",
    "    :return: o3d.geoemtry.PointCloud object\n",
    "    \"\"\"\n",
    "    if direction is None:\n",
    "        direction = (1., 0., 0.)\n",
    "\n",
    "    from PIL import Image, ImageFont, ImageDraw\n",
    "    from pyquaternion import Quaternion\n",
    "\n",
    "    font_obj = ImageFont.truetype(font, font_size * density)\n",
    "    font_dim = font_obj.getsize(text)\n",
    "\n",
    "    img = Image.new('RGB', font_dim, color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((0, 0), text, font=font_obj, fill=(0, 0, 0))\n",
    "    img = np.asarray(img)\n",
    "    img_mask = img[:, :, 0] < 128\n",
    "    indices = np.indices([*img.shape[0:2], 1])[:, img_mask, 0].reshape(3, -1).T\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.colors = o3d.utility.Vector3dVector(img[img_mask, :].astype(float) / 255.0)\n",
    "    pcd.points = o3d.utility.Vector3dVector(indices / 1000 / density)\n",
    "\n",
    "    raxis = np.cross([0.0, 0.0, 1.0], direction)\n",
    "    if np.linalg.norm(raxis) < 1e-6:\n",
    "        raxis = (0.0, 0.0, 1.0)\n",
    "    trans = (Quaternion(axis=raxis, radians=np.arccos(direction[2])) *\n",
    "             Quaternion(axis=direction, degrees=degree)).transformation_matrix\n",
    "    trans[0:3, 3] = np.asarray(pos)\n",
    "    pcd.transform(trans)\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ed5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = dataset.__getitem__(8) # 1637, 167\n",
    "\n",
    "opcd = convert_to_o3dpcd(in_dict['points'])\n",
    "o3dboxes = [boxpts_to_o3dbox(opd_to_boxpts(box)) for box in in_dict['gt_boxes']]\n",
    "\n",
    "objs = [opcd.crop(o3dbox) for o3dbox in o3dboxes]\n",
    "text_loc = [o3dbox.center + np.array([0,0,o3dbox.extent[2]]) for o3dbox in o3dboxes]\n",
    "num_pts = [len(obj.points) for obj in objs]\n",
    "# labels = [text_3d(str(npt), loc, font_size=500, density=1) for npt, loc in zip(num_pts, text_loc)]\n",
    "\n",
    "o3d.visualization.draw_geometries([opcd] + o3dboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fb02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_points_by_range(points, limit_range):\n",
    "    # Input: [xmin, ymin, zmin, xmax, ymax, zmax] \n",
    "    # Though this only limits x and y\n",
    "    mask = (points[:, 0] >= limit_range[0]) & (points[:, 0] <= limit_range[3]) \\\n",
    "           & (points[:, 1] >= limit_range[1]) & (points[:, 1] <= limit_range[4])\n",
    "    return mask\n",
    "\n",
    "LIMITS = [-24, -24, -2, 24, 24, 4]\n",
    "pts = in_dict['points'][mask_points_by_range(in_dict['points'], LIMITS)]\n",
    "limpcd = convert_to_o3dpcd(pts, [0.9,0.9,0])\n",
    "o3d.visualization.draw_geometries([opcd, limpcd] + o3dboxes + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "196b2f4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MeshedKittiDataset' object has no attribute 'infos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_54/1145916745.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m217\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meshed_lidar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MeshedKittiDataset' object has no attribute 'infos'"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "\n",
    "index = 217\n",
    "info = copy.deepcopy(dataset.infos[index])\n",
    "points = dataset.get_meshed_lidar(index)\n",
    "\n",
    "# Shift points \n",
    "if dataset.dataset_cfg.get('SHIFT_COOR', None):\n",
    "    points[:, 0:3] += np.array(dataset.dataset_cfg.SHIFT_COOR, dtype=np.float32)\n",
    "\n",
    "input_dict = {\n",
    "    'points': points,\n",
    "    'frame_id': Path(info['meshed_lidar_path']).stem,\n",
    "    'metadata': {'token': info['token']},\n",
    "    'num_lidar_pts': info['num_lidar_pts'],\n",
    "    'num_meshed_lidar_pts': info['num_meshed_lidar_pts'],\n",
    "    'gt_names': info['gt_names']\n",
    "}\n",
    "\n",
    "if 'gt_boxes' in info:\n",
    "    if dataset.dataset_cfg.get('FILTER_MIN_POINTS_IN_GT', False):\n",
    "        mask = (info['num_lidar_pts'] > dataset.dataset_cfg.FILTER_MIN_POINTS_IN_GT)\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    input_dict.update({\n",
    "        'gt_names': info['gt_names'] if mask is None else info['gt_names'][mask],\n",
    "        'gt_boxes': info['gt_boxes'] if mask is None else info['gt_boxes'][mask],\n",
    "        'num_lidar_pts': info['num_lidar_pts'] if mask is None else info['num_lidar_pts'][mask],\n",
    "        'num_meshed_lidar_pts': info['num_meshed_lidar_pts'] if mask is None else info['num_meshed_lidar_pts'][mask]\n",
    "    })\n",
    "    \n",
    "print(input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e92df",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0254b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-19 22:49:08,813  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "[2022-06-19 22:49:08,813  meshed_kitti_dataset.py 37  INFO]  Loading MeshedKittiDataset dataset\n",
      "INFO - 2022-06-19 22:49:08,813 - meshed_kitti_dataset - Loading MeshedKittiDataset dataset\n",
      "[2022-06-19 22:49:08,935  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "[2022-06-19 22:49:08,935  meshed_kitti_dataset.py 51  INFO]  Total samples for MeshedKittiDataset dataset: 3769\n",
      "INFO - 2022-06-19 22:49:08,935 - meshed_kitti_dataset - Total samples for MeshedKittiDataset dataset: 3769\n"
     ]
    }
   ],
   "source": [
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.models import build_network\n",
    "\n",
    "ckpt_path = '/SEE-MTDA/detector/output/source-waymo/pvrcnn/see-v2/pvrcnn_ros_custom1000_WAY-GM-EXT-R6D-E3_SURFACEKNN_CN_150ep/default/ckpt/checkpoint_epoch_103.pth'\n",
    "# ckpt_path = '/SEE-MTDA/model_zoo/waymo_secondiou_baseline_1192.pth'\n",
    "\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "            dataset_cfg=cfg.DATA_CONFIG_TAR,\n",
    "            class_names=cfg.DATA_CONFIG_TAR.CLASS_NAMES,\n",
    "            batch_size=1,\n",
    "            dist=False, workers=2, logger=logger, training=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c058a3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-19 22:49:09,602  detector3d_template.py 325  INFO]  ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/pvrcnn/see-v2/pvrcnn_ros_custom1000_WAY-GM-EXT-R6D-E3_SURFACEKNN_CN_150ep/default/ckpt/checkpoint_epoch_103.pth to GPU\n",
      "[2022-06-19 22:49:09,602  detector3d_template.py 325  INFO]  ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/pvrcnn/see-v2/pvrcnn_ros_custom1000_WAY-GM-EXT-R6D-E3_SURFACEKNN_CN_150ep/default/ckpt/checkpoint_epoch_103.pth to GPU\n",
      "INFO - 2022-06-19 22:49:09,602 - detector3d_template - ==> Loading parameters from checkpoint /SEE-MTDA/detector/output/source-waymo/pvrcnn/see-v2/pvrcnn_ros_custom1000_WAY-GM-EXT-R6D-E3_SURFACEKNN_CN_150ep/default/ckpt/checkpoint_epoch_103.pth to GPU\n",
      "[2022-06-19 22:49:11,112  detector3d_template.py 331  INFO]  ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "[2022-06-19 22:49:11,112  detector3d_template.py 331  INFO]  ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "INFO - 2022-06-19 22:49:11,112 - detector3d_template - ==> Checkpoint trained from version: pcdet+0.3.0+0000000\n",
      "[2022-06-19 22:49:11,531  detector3d_template.py 350  INFO]  ==> Done (loaded 319/319)\n",
      "[2022-06-19 22:49:11,531  detector3d_template.py 350  INFO]  ==> Done (loaded 319/319)\n",
      "INFO - 2022-06-19 22:49:11,531 - detector3d_template - ==> Done (loaded 319/319)\n"
     ]
    }
   ],
   "source": [
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "model.load_params_from_file(filename=ckpt_path, logger=logger, to_cpu=False)\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "class_names = dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b735cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcdet.models import load_data_to_gpu\n",
    "\n",
    "def statistics_info(cfg, ret_dict, metric, disp_dict):\n",
    "    for cur_thresh in cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST:\n",
    "        metric['recall_roi_%s' % str(cur_thresh)] += ret_dict.get('roi_%s' % str(cur_thresh), 0)\n",
    "        metric['recall_rcnn_%s' % str(cur_thresh)] += ret_dict.get('rcnn_%s' % str(cur_thresh), 0)\n",
    "    metric['gt_num'] += ret_dict.get('gt', 0)\n",
    "    min_thresh = cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST[0]\n",
    "    disp_dict['recall_%s' % str(min_thresh)] = \\\n",
    "        '(%d, %d) / %d' % (metric['recall_roi_%s' % str(min_thresh)], metric['recall_rcnn_%s' % str(min_thresh)], metric['gt_num'])\n",
    "\n",
    "metric = {\n",
    "    'gt_num': 0,\n",
    "}\n",
    "det_annos = []\n",
    "for cur_thresh in cfg.MODEL.POST_PROCESSING.RECALL_THRESH_LIST:\n",
    "    metric['recall_roi_%s' % str(cur_thresh)] = 0\n",
    "    metric['recall_rcnn_%s' % str(cur_thresh)] = 0\n",
    "\n",
    "\n",
    "for i, batch_dict in enumerate(test_loader):\n",
    "    if i == 5:\n",
    "        load_data_to_gpu(batch_dict)\n",
    "        with torch.no_grad():\n",
    "            pred_dicts, ret_dict = model(batch_dict)\n",
    "        disp_dict = {}\n",
    "\n",
    "        statistics_info(cfg, ret_dict, metric, disp_dict)\n",
    "        annos = dataset.generate_prediction_dicts(\n",
    "            batch_dict, pred_dicts, class_names,\n",
    "            output_path=None\n",
    "        )\n",
    "        det_annos += annos\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be6d63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = dataset.__getitem__(i) # 1637, 167\n",
    "\n",
    "gt_boxes = batch_dict['gt_boxes'].squeeze(0).cpu().numpy()\n",
    "pred_boxes = pred_dicts[0]['pred_boxes'].cpu().numpy()\n",
    "\n",
    "o3d_gtb = [boxpts_to_o3dbox(opd_to_boxpts(box),[0,0,1]) for box in gt_boxes]\n",
    "o3d_pb = [boxpts_to_o3dbox(opd_to_boxpts(box),[0,0.7,0]) for box in pred_boxes]\n",
    "opcd = convert_to_o3dpcd(in_dict['points'])\n",
    "\n",
    "o3d.visualization.draw_geometries(o3d_gtb + o3d_pb + [opcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e3f89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = dataset.__getitem__(i) # 1637, 167\n",
    "\n",
    "opcd = convert_to_o3dpcd(in_dict['points'])\n",
    "o3dboxes = [boxpts_to_o3dbox(opd_to_boxpts(box)) for box in in_dict['gt_boxes']]\n",
    "\n",
    "objs = [opcd.crop(o3dbox) for o3dbox in o3dboxes]\n",
    "text_loc = [o3dbox.center + np.array([0,0,o3dbox.extent[2]]) for o3dbox in o3dboxes]\n",
    "num_pts = [len(obj.points) for obj in objs]\n",
    "labels = [text_3d(str(npt), loc, font_size=500, density=1) for npt, loc in zip(num_pts, text_loc)]\n",
    "\n",
    "o3d.visualization.draw_geometries([opcd] + o3dboxes + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e5397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from ../../data/nuscenes/custom_t4025-v3980/infos_meshed_NUS-DM-ORH005/nuscenes_infos_2sweeps_val.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for info_path in dataset.dataset_cfg.INFO_PATH['test']:\n",
    "    info_path = dataset.root_path / info_path\n",
    "    print(f'Reading from {info_path}')\n",
    "    if not info_path.exists():\n",
    "        continue\n",
    "    with open(info_path, 'rb') as f:\n",
    "        infos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "195af475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 3980/3980 [01:02<00:00, 63.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import open3d as o3d\n",
    "\n",
    "updated_infos = []\n",
    "\n",
    "for i in tqdm(range(len(infos)), total=len(infos)):\n",
    "    info = infos[i]\n",
    "    meshed_lidar_file = dataset.root_path / info['meshed_lidar_path']\n",
    "    opcd = o3d.io.read_point_cloud(str(meshed_lidar_file))\n",
    "    gt_boxes = info['gt_boxes']\n",
    "    o3dboxes = [boxpts_to_o3dbox(opd_to_boxpts(box)) for box in gt_boxes]\n",
    "    objs = [opcd.crop(o3dbox) for o3dbox in o3dboxes]    \n",
    "    num_pts = [len(obj.points) for obj in objs]\n",
    "#     text_loc = [o3dbox.center + np.array([0,0,o3dbox.extent[2]]) for o3dbox in o3dboxes]\n",
    "#     labels = [text_3d(str(npt), loc, font_size=500, density=1) for npt, loc in zip(num_pts, text_loc)]\n",
    "    info['num_meshed_lidar_pts'] = np.array(num_pts)\n",
    "    updated_infos.append(info)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadd2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toutput = open(str(Path(dataset.dataset_cfg.DATA_PATH).absolute() / 'infos_meshed_NUS-DM-ORH005' / f'nuscenes_infos_2sweeps_val_meshednum.pkl'), 'wb')\n",
    "pickle.dump(updated_infos, toutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da5d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([opcd] + o3dboxes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "896b9a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('car', 3, 6)\n",
      "('traffic_cone', 19, 38)\n",
      "('car', 63, 461)\n",
      "('car', 18, 32)\n",
      "('barrier', 2, 4)\n",
      "('pedestrian', 5, 12)\n",
      "('car', 4, 7)\n",
      "('pedestrian', 19, 35)\n",
      "('car', 10, 23)\n",
      "('car', 1, 4)\n",
      "('car', 5, 9)\n",
      "('car', 2, 3)\n",
      "('car', 8, 15)\n",
      "('traffic_cone', 9, 17)\n",
      "('pedestrian', 5, 10)\n",
      "('barrier', 6, 13)\n",
      "('traffic_cone', 2, 3)\n",
      "('truck', 8, 15)\n",
      "('car', 7, 17)\n",
      "('car', 19, 49)\n",
      "('car', 16, 32)\n",
      "('car', 1, 2)\n",
      "('car', 4, 9)\n",
      "('pedestrian', 1, 8)\n",
      "('barrier', 3, 6)\n",
      "('car', 2, 4)\n",
      "('car', 3, 10)\n",
      "('car', 8, 20)\n",
      "('barrier', 6, 14)\n",
      "('pedestrian', 5, 10)\n",
      "('pedestrian', 5, 10)\n",
      "('ignore', 8, 16)\n",
      "('car', 6, 10)\n",
      "('car', 10, 22)\n",
      "('car', 2, 4)\n",
      "('barrier', 25, 50)\n",
      "('barrier', 27, 50)\n",
      "('car', 9, 17)\n",
      "('car', 1, 2)\n",
      "('car', 1, 4)\n",
      "('traffic_cone', 4, 6)\n",
      "('car', 3, 8)\n",
      "('pedestrian', 12, 23)\n",
      "('car', 2, 4)\n",
      "('car', 4, 8)\n",
      "('car', 30, 322)\n",
      "('car', 5, 9)\n",
      "('barrier', 15, 31)\n",
      "('barrier', 8, 16)\n",
      "('car', 2, 4)\n",
      "('barrier', 11, 21)\n",
      "('car', 1, 2)\n",
      "('pedestrian', 4, 9)\n",
      "('car', 2, 5)\n",
      "('car', 99, 678)\n",
      "('car', 2, 4)\n",
      "('car', 2, 4)\n",
      "('car', 596, 2117)\n",
      "('car', 1, 1)\n",
      "('car', 1, 2)\n",
      "('traffic_cone', 5, 8)\n",
      "('car', 10, 14)\n",
      "('pedestrian', 17, 35)\n",
      "('car', 3, 4)\n",
      "('car', 4, 6)\n",
      "('barrier', 14, 32)\n",
      "('car', 0, 0)\n",
      "('car', 5, 4)\n",
      "('barrier', 1, 1)\n",
      "('barrier', 34, 77)\n",
      "('car', 7, 15)\n"
     ]
    }
   ],
   "source": [
    "for d in zip(info['gt_names'], info['num_lidar_pts'], info['num_meshed_lidar_pts']):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2253fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51d926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

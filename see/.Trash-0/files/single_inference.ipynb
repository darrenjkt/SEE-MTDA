{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45a9d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from network import Network\n",
    "from torch.utils.data import DataLoader\n",
    "from config import get_config, print_usage\n",
    "from data_utils.ShapeNetLoader import ShapeNetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "031736c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse configuration\n",
    "config, unparsed = get_config()\n",
    "config.log_dir = \"plane_dim3\"\n",
    "config.indim=3\n",
    "config.cat_id=2\n",
    "config.mode=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcba701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "num K: 10\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "cn_type: acn_b-10\n",
      "num_head: 10\n",
      "bn type: bn\n",
      "num K: 10\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from models.acne_ae import AcneAe \n",
    "import torch\n",
    "\n",
    "if config.input_feat in [\"ppf\"] \\\n",
    "    or config.pose_code in [\"weighted_qt\"]:\n",
    "    require_normal = True\n",
    "else:\n",
    "    require_normal = False\n",
    "\n",
    "# load data\n",
    "dataset = ShapeNetLoader(\n",
    "    data_dump_folder=config.data_dump_folder, indim=config.indim, freeze_data=False, id=config.cat_id, require_normal=require_normal,\n",
    "    num_pts=config.num_pts, mode=\"test\", jitter_type=config.pc_jitter_type)\n",
    "data_loader_te = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=config.test_batch_size,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    pin_memory=False,\n",
    ")\n",
    "    \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed_all(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "model = eval(config.model)\n",
    "model = model(config) # 2_1 output one_dimensional score\n",
    "\n",
    "if config.use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb163f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See data input\n",
    "import open3d as o3d\n",
    "\n",
    "def convert_to_o3dpcd(pts, color=None):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "    if color is not None:\n",
    "        pcd.paint_uniform_color(color)\n",
    "    return pcd\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c60db2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KITTI incomplete pcds\n",
    "import glob\n",
    "\n",
    "kitti_pcds = glob.glob('/canonical_capsules/data_dump/kitti/cars/*')\n",
    "kidx = 0\n",
    "o3dpc = o3d.io.read_point_cloud(kitti_pcds[kidx])\n",
    "pc_pts = np.asarray(o3dpc.points - o3dpc.get_center(), dtype=np.float)\n",
    "o3d.visualization.draw_geometries([o3dpc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "797f83cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "testing:   0%|                                              | 0/703 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising data #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "testing:   1%|▌                                    | 10/703 [00:26<30:26,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising data #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "testing:   3%|█                                    | 20/703 [00:39<25:27,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising data #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "testing:   4%|█▌                                   | 30/703 [00:49<20:56,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualising data #40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing:   6%|██                                   | 39/703 [01:11<20:25,  1.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44/2927113472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mout_pcd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_o3dpcd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#             mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.6, origin=[0,0,0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_geometries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_pcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pcd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# taken from network.test and model.forward_test\n",
    "\n",
    "from tqdm import tqdm\n",
    "from geom_torch import trans_pc_random, procruste_pose, get_rots \n",
    "import os\n",
    "from loss_util import *\n",
    "from vis_util import *\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Read checkpoint file.\n",
    "load_res = torch.load(config.pt_file)\n",
    "\n",
    "# Resume iterations\n",
    "iter_idx = load_res[\"iter_idx\"]\n",
    "# Resume model\n",
    "model.load_state_dict(load_res[\"model\"], strict=False)\n",
    "\n",
    "prefix = \"testing\"\n",
    "oas = []\n",
    "jdx = 0\n",
    "vis_idx = [1, 2, 3]\n",
    "# for data in data_loader: \n",
    "accs = {}\n",
    "feats = {}\n",
    "# model.aligner = None\n",
    "\n",
    "for data in tqdm(data_loader_te, desc=prefix):         \n",
    "    \n",
    "    jdx += 1\n",
    "    if (jdx%10 == 0):\n",
    "        \n",
    "        batch_size = len(data[\"pc\"])    \n",
    "        # move tensor into cuda\n",
    "        if config.use_cuda:\n",
    "            for key in data.keys():\n",
    "                data[key] = data[key].cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "#             pc = data[\"pc\"]\n",
    "            o3dpc = o3d.io.read_point_cloud(kitti_pcds[jdx])\n",
    "            pc_pts = np.asarray(o3dpc.points - o3dpc.get_center(), dtype=np.float)\n",
    "            pc_pts = torch.from_numpy(pc_pts[np.newaxis,...])\n",
    "            pc = pc_pts.cuda().float()\n",
    "            \n",
    "            rt = None\n",
    "            att_aligner = None\n",
    "            if model.aligner is not None:\n",
    "                model.aligner.eval()\n",
    "                with torch.no_grad():\n",
    "                    pc, ret_aligner = model.aligner.forward_align(pc, rt=rt)\n",
    "                    att_aligner = ret_aligner[\"att_aligner\"]\n",
    "\n",
    "            x = pc.transpose(2, 1)\n",
    "\n",
    "            # encoding x\n",
    "            input_feat = x[..., None]\n",
    "            gc_att = model.encoder(input_feat, att_aligner=att_aligner, return_att=True) # BCK1, B1GN1\n",
    "            gc, att = gc_att\n",
    "\n",
    "            # Evaluating pose \n",
    "            pose_local = evaluate_pose(x, att)\n",
    "            kps = pose_local.squeeze(-1)\n",
    "\n",
    "            # w/o canonicalized descriptor\n",
    "            if config.pose_block == \"procruste\":\n",
    "                if model.ref_kp_type != \"None\":\n",
    "                    if self.ref_kp_type.startswith(\"mlp\"):\n",
    "                        kps_ref= model.ref_kp_net(gc.reshape(gc.shape[0], -1))\n",
    "                        kps_ref = kps_ref - kps_ref.mean(dim=2, keepdim=True)\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                    R_can, T_can = procruste_pose(kps, kps_ref, std_noise=0) # kps_ref = R * kpsi  + T\n",
    "                    kps = torch.matmul(R_can, kps) + T_can\n",
    "                else:\n",
    "                    R_can = None\n",
    "\n",
    "            # reconstruction from canonical capsules \n",
    "            gc = torch.cat([kps[..., None], gc], dim=1)\n",
    "            y = model.decoder(gc.transpose(2, 1).squeeze(-1))\n",
    "\n",
    "            print(f'Visualising data #{jdx}')\n",
    "            input_pcd = convert_to_o3dpcd(np.array(pc[0].cpu()), color=[0.85,0.85,0.85])\n",
    "            out_pcd = convert_to_o3dpcd(np.array(y[0].cpu()), color=[1,0,0])\n",
    "#             mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.6, origin=[0,0,0])\n",
    "            o3d.visualization.draw_geometries([input_pcd, out_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad484a",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "45442787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "vis:   0%|                                                  | 0/809 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: [[[1. 0. 0.]\n",
      "  [0. 1. 0.]\n",
      "  [0. 0. 1.]]]; loss: 0.0019144623074680567\n",
      "R: [[[ 0.9045085  -0.29389262  0.309017  ]\n",
      "  [ 0.38471043  0.875      -0.29389262]\n",
      "  [-0.18401699  0.38471043  0.9045085 ]]]; loss: 0.0018811644986271858\n",
      "R: [[[ 0.6545085  -0.47552827  0.58778524]\n",
      "  [ 0.7550368   0.4514337  -0.47552827]\n",
      "  [-0.03921894  0.7550368   0.6545085 ]]]; loss: 0.001962190493941307\n",
      "R: [[[ 0.3454915  -0.47552827  0.809017  ]\n",
      "  [ 0.8602387  -0.18401699 -0.47552827]\n",
      "  [ 0.375       0.8602387   0.3454915 ]]]; loss: 0.002017565770074725\n",
      "R: [[[ 0.09549151 -0.29389262  0.95105654]\n",
      "  [ 0.57340115 -0.7647472  -0.29389262]\n",
      "  [ 0.81369066  0.57340115  0.09549151]]]; loss: 0.00177321198862046\n",
      "R: [[[ 3.7493994e-33 -6.1232343e-17  1.0000000e+00]\n",
      "  [ 1.2246469e-16 -1.0000000e+00 -6.1232343e-17]\n",
      "  [ 1.0000000e+00  1.2246469e-16  3.7493994e-33]]]; loss: 0.001931279432028532\n",
      "R: [[[ 0.09549151  0.29389262  0.95105654]\n",
      "  [-0.57340115 -0.7647472   0.29389262]\n",
      "  [ 0.81369066 -0.57340115  0.09549151]]]; loss: 0.0019812036771327257\n",
      "R: [[[ 0.3454915   0.47552827  0.809017  ]\n",
      "  [-0.8602387  -0.18401699  0.47552827]\n",
      "  [ 0.375      -0.8602387   0.3454915 ]]]; loss: 0.0019530011340975761\n",
      "R: [[[ 0.6545085   0.47552827  0.58778524]\n",
      "  [-0.7550368   0.4514337   0.47552827]\n",
      "  [-0.03921894 -0.7550368   0.6545085 ]]]; loss: 0.0018643367802724242\n",
      "R: [[[ 0.9045085   0.29389262  0.309017  ]\n",
      "  [-0.38471043  0.875       0.29389262]\n",
      "  [-0.18401699 -0.38471043  0.9045085 ]]]; loss: 0.0019056564196944237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "vis:   0%|                                                  | 0/809 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_907/1630157075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mout_pcd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_o3dpcd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mmesh_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTriangleMesh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_coordinate_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mo3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_geometries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmesh_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_pcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pcd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Taken from vis_single - however I think this rotates \n",
    "# multiple times so it can construct a gif\n",
    "\n",
    "from tqdm import tqdm\n",
    "from geom_torch import trans_pc_random, procruste_pose, get_rots \n",
    "import os\n",
    "from loss_util import *\n",
    "from vis_util import *\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Read checkpoint file.\n",
    "load_res = torch.load(config.pt_file)\n",
    "\n",
    "# Resume iterations\n",
    "iter_idx = load_res[\"iter_idx\"]\n",
    "# Resume model\n",
    "model.load_state_dict(load_res[\"model\"], strict=False)\n",
    "\n",
    "prefix = \"vis\"\n",
    "dump_res = []\n",
    "idx = 0\n",
    "if config.vis_idx > 0:\n",
    "    vis_idx = [config.vis_idx]\n",
    "else:\n",
    "    vis_idx = [i for i in range(1, 4)]\n",
    "\n",
    "# model.aligner = None\n",
    "    \n",
    "for data in tqdm(data_loader_te, desc=prefix): \n",
    "    idx += 1\n",
    "    if idx not in vis_idx:\n",
    "        continue\n",
    "    # move tensor into cuda\n",
    "    if config.use_cuda:\n",
    "        for key in data.keys():\n",
    "            data[key] = data[key].cuda()\n",
    "    in_dict = {} \n",
    "    in_dict[\"data\"] = data\n",
    "    in_dict[\"mode\"] = \"vis\" \n",
    "    in_dict[\"iter_idx\"] = iter_idx\n",
    "    in_dict[\"writer\"] = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # rotate input and show the decomposition and reconstruction \n",
    "        data = in_dict[\"data\"]\n",
    "        mode = in_dict[\"mode\"]\n",
    "        writer = in_dict[\"writer\"]\n",
    "        iter_idx = in_dict[\"iter_idx\"]\n",
    "        pc = data[\"pc\"]\n",
    "\n",
    "        assert pc.shape[2] == config.indim\n",
    "        x_can = pc.transpose(2, 1)\n",
    "        idx = 0\n",
    "        Rs = get_rots(config.indim)\n",
    "\n",
    "        for R in Rs:\n",
    "            idx += 1\n",
    "            x = torch.matmul(\n",
    "                torch.from_numpy(R).to(x_can.device), x_can)\n",
    "\n",
    "            att_aligner = None\n",
    "            if model.aligner is not None:\n",
    "                with torch.no_grad():\n",
    "                    model.aligner.eval()\n",
    "                    x_, ret_aligner = model.aligner.forward_align(x.transpose(2, 1), mode=\"vis\")\n",
    "                    att_aligner = ret_aligner[\"att_aligner\"]\n",
    "\n",
    "                    # visualization\n",
    "                    idx = 0\n",
    "                    x_pts = x[idx].transpose(1, 0).cpu().numpy()                    \n",
    "                    \n",
    "                    x = x_.transpose(2, 1)\n",
    "\n",
    "            input_feat = x[..., None]\n",
    "            gc_att = model.encoder(input_feat, att_aligner=att_aligner, return_att=True) # BCK1, B1GN1\n",
    "            gc, att = gc_att\n",
    "            \n",
    "            # Evaluating pose \n",
    "            pose_local = evaluate_pose(x, att)\n",
    "            kps = pose_local.squeeze(-1)\n",
    "            gc = torch.cat([kps[..., None], gc], dim=1)\n",
    "            pc_recons = model.decoder(\n",
    "                gc.transpose(2, 1).squeeze(-1), return_splits=True)\n",
    "            y = torch.cat(pc_recons, dim=2).transpose(2, 1)\n",
    "            loss_chamfer = model.chamfer_loss(x.transpose(2, 1), y)\n",
    "            print(f\"R: {R}; loss: {loss_chamfer}\")\n",
    "            \n",
    "            # Reconstruct in canonical\n",
    "            label_map = []\n",
    "            pts = []\n",
    "            for i, patch in enumerate(pc_recons):\n",
    "#                 print(patch.shape)\n",
    "                pts_cur = patch[0].transpose(1, 0).cpu().numpy()\n",
    "                label_map += [np.ones(len(pts_cur)) * i]\n",
    "                pts += [pts_cur]\n",
    "\n",
    "            recon_pts = np.concatenate(pts, axis=0)\n",
    "    \n",
    "            input_pcd = convert_to_o3dpcd(np.array(data[\"pc\"][0].cpu()), color=[0.85,0.85,0.85])\n",
    "            out_pcd = convert_to_o3dpcd(recon_pts)\n",
    "            mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.6, origin=[0,0,0])\n",
    "            o3d.visualization.draw_geometries([mesh_frame, input_pcd, out_pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcd",
   "language": "python",
   "name": "pcd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
